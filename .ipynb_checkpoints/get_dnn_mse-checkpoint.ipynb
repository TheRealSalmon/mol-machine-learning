{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeee049c-9b11-4403-9bb6-b90ebb27f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepchem as dc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.CRITICAL)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d1d3a2-eb21-428d-a997-47acc0c93694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_split_dfs(input_dir):\n",
    "    test = []\n",
    "    for i in range(5):\n",
    "        test.append(pd.read_pickle(f'{input_dir}/test{i}'))\n",
    "    return test\n",
    "\n",
    "def ds_from_df_split(split_dfs, featurizer):\n",
    "    split_dss = []\n",
    "    for i in range(5):\n",
    "        df = split_dfs[i]\n",
    "        X = featurizer.featurize(df.smiles)\n",
    "        ds = dc.data.DiskDataset.from_numpy(X=X, y=np.vstack(df.label.to_numpy()), ids=df.smiles)\n",
    "        split_dss.append(ds)\n",
    "    all_dss = dc.data.DiskDataset.merge(split_dss)\n",
    "    \n",
    "    transformer = dc.trans.NormalizationTransformer(transform_y=True, dataset=all_dss)\n",
    "    for i in range(5):\n",
    "        split_dss[i] = transformer.transform(split_dss[i])\n",
    "    \n",
    "    return all_dss, split_dss, transformer\n",
    "\n",
    "def get_kfold_from_ds_split(split_dss):\n",
    "    kfold = []\n",
    "    for i in range(5):\n",
    "        temp_dss = split_dss.copy()\n",
    "        temp_test = temp_dss.pop(i)\n",
    "        kfold.append((dc.data.DiskDataset.merge(temp_dss), temp_test))\n",
    "    return kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16b3ea7a-0a6a-476b-bf69-c91da8f98304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_model_from_trial(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1, 500, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 50),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 1000, log=True),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 1000, log=True),\n",
    "        'max_leaf_nodes': trial.suggest_int('max_leaf_nodes', 2, 100, log=True),\n",
    "    }\n",
    "    sklearn_random_forest = RandomForestRegressor(**param, n_jobs=-1)\n",
    "    rf_model = dc.models.SklearnModel(sklearn_random_forest)\n",
    "    return rf_model\n",
    "\n",
    "def random_forest_model_from_param(param):\n",
    "    sklearn_random_forest = RandomForestRegressor(**param, n_jobs=-1)\n",
    "    rf_model = dc.models.SklearnModel(sklearn_random_forest)\n",
    "    return rf_model\n",
    "\n",
    "def random_forest_optuna(trial, kfold):\n",
    "    rf_model = random_forest_model_from_trial(trial)\n",
    "    mse = []\n",
    "    for k in kfold:\n",
    "        rf_model.fit(k[0].complete_shuffle())\n",
    "        y_pred = rf_model.predict(k[1])\n",
    "        y_meas = k[1].y\n",
    "        mse.append(dc.metrics.mean_squared_error(y_meas, y_pred))\n",
    "        \n",
    "    return sum(mse)/len(mse)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a871e965-37c5-440b-835d-4eecdc8c61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward_neural_network_from_trial(trial, len_feat_vec):\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 3)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-10, 1e-3, log=True)\n",
    "    fnn_model = tf.keras.Sequential()\n",
    "    fnn_model.add(tf.keras.layers.Input(shape=(len_feat_vec,)))\n",
    "    # dropout = trial.suggest_float(f'dropout_{0}', 0.0, 1.0)\n",
    "    # model.add(tf.keras.layers.Dropout(dropout))\n",
    "    for i in range(n_layers):\n",
    "        num_nodes = trial.suggest_int(f'n_nodes_{i+1}', 4, 128, log=True)\n",
    "        dropout = trial.suggest_float(f'dropout_{i+1}', 0.0, 1.0)\n",
    "        fnn_model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                num_nodes,\n",
    "                activation='relu',\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay)\n",
    "            )\n",
    "        )\n",
    "        fnn_model.add(tf.keras.layers.Dropout(dropout))\n",
    "    fnn_model.add(\n",
    "        tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.l2(weight_decay))\n",
    "    )\n",
    "    rate = trial.suggest_float('learning_rate', 1e-8, 1e-1, log=True)\n",
    "    dc_model = dc.models.KerasModel(model=fnn_model, loss=dc.models.losses.L2Loss(), learning_rate=rate)\n",
    "    return dc_model\n",
    "\n",
    "def feedforward_neural_network_from_param(param):\n",
    "    pass\n",
    "\n",
    "def feedforward_neural_network_optuna(trial, kfold, transformer, len_feat_vec):\n",
    "    mse = []\n",
    "    \n",
    "    for i,k in enumerate(kfold):\n",
    "        fnn_model = feedforward_neural_network_from_trial(trial, len_feat_vec)\n",
    "        metric = dc.metrics.Metric(dc.metrics.mean_squared_error)\n",
    "        # callback = dc.models.callbacks.ValidationCallback(dataset=k[1], interval=10, metrics=[metric], transformers=[transformer])\n",
    "        callback = dc.models.callbacks.ValidationCallback(dataset=k[1], interval=100, metrics=[metric], save_dir='tmp')\n",
    "        fnn_model.fit(dataset=k[0].complete_shuffle(), nb_epoch=100, callbacks=callback)\n",
    "        mse.append(callback._best_score)\n",
    "        \n",
    "    return sum(mse)/len(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f82bea21-6e6b-4cfc-9f52-4ec2e93e570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feedforward_NN_model(trial):\n",
    "    pass\n",
    "\n",
    "def feedforward_NN_optuna(trial):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff350249-a1d1-45b6-a63d-ffa260c3338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dfs = load_split_dfs('sma1_random_split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f187d9a-3876-4782-a50d-c123f9ae6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_FEAT_VEC = 2048\n",
    "featurizer = dc.feat.CircularFingerprint(radius=2, size=LEN_FEAT_VEC, chiral=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5e3071-8c9d-4bf6-bede-817241fa8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dss, split_dss, transformer = ds_from_df_split(split_dfs, featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ea42152-3813-4043-9fe2-8ec9393248a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tests = get_kfold_from_ds_split(split_dss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb920be6-42dc-4251-b8b7-7388e91e9081",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_info = []\n",
    "\n",
    "for i,tt in enumerate(train_tests):\n",
    "    splitter = dc.splits.RandomSplitter()\n",
    "    kfold = splitter.k_fold_split(dataset=tt[0], k=5)\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: feedforward_neural_network_optuna(trial, kfold, transformer, LEN_FEAT_VEC), n_trials=1)\n",
    "    \n",
    "    test_mse = []\n",
    "    for j in range(5):\n",
    "        tuned_fnn_model = feedforward_neural_network_from_trial(study.best_trial, LEN_FEAT_VEC)\n",
    "        metric = dc.metrics.Metric(dc.metrics.mean_squared_error)\n",
    "        # callback = dc.models.callbacks.ValidationCallback(dataset=k[1], interval=10, metrics=[metric], transformers=[transformer])\n",
    "        callback = dc.models.callbacks.ValidationCallback(dataset=tt[1], interval=100, metrics=[metric], save_dir='tmp')\n",
    "        tuned_fnn_model.fit(dataset=tt[0].complete_shuffle(), nb_epoch=100, callbacks=callback)\n",
    "        test_mse.append(callback._best_score)\n",
    "    \n",
    "    output_info.append((i, study.best_value, str(study.best_params), sum(test_mse)/len(test_mse), test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b06c6787-3ef4-4f4d-84a2-cb152e94d2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_index</th>\n",
       "      <th>avg_valid_mse</th>\n",
       "      <th>best_params</th>\n",
       "      <th>avg_test_mse</th>\n",
       "      <th>test_mses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1.019483</td>\n",
       "      <td>{'n_layers': 3, 'weight_decay': 3.772144576138...</td>\n",
       "      <td>0.842647</td>\n",
       "      <td>[0.8296379533441094, 0.8381851213995676, 0.851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.902524</td>\n",
       "      <td>{'n_layers': 2, 'weight_decay': 3.235418746670...</td>\n",
       "      <td>0.975070</td>\n",
       "      <td>[0.9859052387413431, 0.9738764414742868, 0.951...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.957456</td>\n",
       "      <td>{'n_layers': 1, 'weight_decay': 1.299267424835...</td>\n",
       "      <td>0.851133</td>\n",
       "      <td>[0.8313375567924828, 0.8662653812634217, 0.859...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.998971</td>\n",
       "      <td>{'n_layers': 1, 'weight_decay': 1.131269472048...</td>\n",
       "      <td>1.168706</td>\n",
       "      <td>[1.171167094846065, 1.1825770070344988, 1.1512...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.993971</td>\n",
       "      <td>{'n_layers': 3, 'weight_decay': 2.151749665807...</td>\n",
       "      <td>1.055636</td>\n",
       "      <td>[1.049748495713449, 1.0418304834274834, 1.0517...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split_index  avg_valid_mse  \\\n",
       "0            4       1.019483   \n",
       "1            4       0.902524   \n",
       "2            4       0.957456   \n",
       "3            4       0.998971   \n",
       "4            4       0.993971   \n",
       "\n",
       "                                         best_params  avg_test_mse  \\\n",
       "0  {'n_layers': 3, 'weight_decay': 3.772144576138...      0.842647   \n",
       "1  {'n_layers': 2, 'weight_decay': 3.235418746670...      0.975070   \n",
       "2  {'n_layers': 1, 'weight_decay': 1.299267424835...      0.851133   \n",
       "3  {'n_layers': 1, 'weight_decay': 1.131269472048...      1.168706   \n",
       "4  {'n_layers': 3, 'weight_decay': 2.151749665807...      1.055636   \n",
       "\n",
       "                                           test_mses  \n",
       "0  [0.8296379533441094, 0.8381851213995676, 0.851...  \n",
       "1  [0.9859052387413431, 0.9738764414742868, 0.951...  \n",
       "2  [0.8313375567924828, 0.8662653812634217, 0.859...  \n",
       "3  [1.171167094846065, 1.1825770070344988, 1.1512...  \n",
       "4  [1.049748495713449, 1.0418304834274834, 1.0517...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df = pd.DataFrame(output_info, columns=['split_index', 'avg_valid_mse', 'best_params', 'avg_test_mse', 'test_mses'])\n",
    "out_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
